---
layout: page
title: Research
subtitle: Learning (Animal, Human, Machine)
---

I'm interested broadly in learning --- but my research has focused along two main lines: representation learning for science, and applications to juvenile songbird learning

# Representation learning for science

How do we build models that learn useful representations for scientists? Generally, these models need to: 
1. capture some hidden, obscured, or difficult to find structure in the data,
2. be (relatively) easy to interpret, and
3. be relatively easy to train

I've focused on those first two points explicitly (and the third implicitly) throughout my PhD.

## Modeling of animal vocalizations with Ouroboros

Because it's an auto-encoding technique (eating its own tail) and uses Mamba models. get it? hahahaha
<img src="{{ '/assets/img/pudhina.jpg'}}" id="ouro-img">
In this approach, we approximate the vocal system as a flexible, nonlinear, damped harmonic oscillator. This modeling technique follows other very beautiful, classic approaches in vocal chord modeling in multiple species. This model works directly in audio space, 

## Low-dimensional latent variable modeling with QLVMs

## Reproducible latent variable modeling with R-VAEs

# Applications to juvenile songbird learning




